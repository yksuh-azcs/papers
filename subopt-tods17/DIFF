9c9
< \acmMonth{4}
---
> \acmMonth{5}
128c128,129
< The query optimization phase within a \hbox{DBMS} ostensibly finds the fastest query
---
> 
> The query optimization phase within a database management system (\hbox{DBMS}) ostensibly finds the fastest query
130,131c131,133
< which correctly compute the specified query. Occasionally the optimizer
< selects the wrong plan, for a variety of reasons. {\em Suboptimality} is
---
> which correctly compute the specified query. Occasionally the cost-based optimizer
> selects a slower plan, for a variety of reasons. We introduce the notion of
> {\em empirical suboptimality} of a query plan chosen by the DBMS,
133c135
< than the DBMS's chosen plan, for the same query. From an engineering
---
> than the chosen plan, for the same query. From an engineering
135a138
> 
137c140
< relationship between various factors in query optimization and
---
> relationship between various factors in query optimization and empirical
139c142
< complexity of the query and optimizer and concomitant unanticipated
---
> complexity of the schema, data, query, and optimizer and concomitant 
141,142c144,148
< hypothesis that were subsequently tested on multiple \hbox{DBMSes}. We
< observe that suboptimality prevalence
---
> hypotheses that were subsequently tested on multiple \hbox{DBMSes}.
> 
> Through a series of experiments that examine the plans for thousands of queries
> run on one hundred thousand query/cardinality combinations on four popular
> DBMSes, we observe that the dependent construct of empirical suboptimality prevalence
144,145c150,151
< (one proxy for optimizer complexity) and with the number of plans generated
< by the optimizer (another proxy for optimizer complexity) and with
---
> (one proxy for optimizer complexity), with the number of plans generated
> by the optimizer (another proxy for optimizer complexity), and with
147,155c153,169
< empirical support for this model (in fact, these causal factors explain over
< half of the variance of suboptimality) as well as implications for fundamental
< improvements of these optimizers. Through a novel analysis, we present
< evidence for a previously-uninown upper bound on the number of operators a DBMS may be able to support.
< This paper thus provides
< a new methodology to study mature query optimizers, that of empirical
< generalization, proposes a novel causal model for query suboptimality, and
< demonstrates that an upper bound on the number of operators is probable and
< may have already been reached by one or more extant DBMSes.
---
> empirical support for this model. These causal factors explain in concert over
> half of the variance of suboptimality.
> 
> An implication of this causal model is that as query evaluation operators
> are added to a DBMS, the prevalence of slower queries will grow. Through a
> novel experiment that examines the plans on the afore-mentioned
> query/cardinality combinations, we present evidence for a previously-unknown
> upper bound on the number of operators a DBMS may be able to support before
> performance suffers.  We
> show that this upper bound may have already been reached by one or more
> extant~DBMSes.
> 
> This paper thus provides a new methodology to study mature query optimizers, that
> of empirical generalization, proposes a novel causal model for empirical query
> suboptimality, and demonstrates that an upper bound that may have already
> been encountered, with implications for fundamental improvements of those
> cost-based query optimizers.
178,180c192,198
< DBMSes underlie information systems and hence optimizing their performance is of
< critical importance. A relational DBMS's query optimizer plays an important role. But
< what if the optimizer {\em doesn't}: what if it selects the wrong plan?
---
> Database management systems (DBMSes) underlie information systems and hence optimizing their performance is of
> critical importance. A relational DBMS's cost-based query optimizer plays an
> important role, ostensibly finding a fast query execution plan from a
> potentially large set of possible plans, all of which correctly compute the
> submitted query, using a cost model that references properties of the
> underlying relations. But
> what if the optimizer {\em doesn't}: what if it selects a slow plan?
182,183c200,201
< This paper provides a thorough investigation into \hbox{DBMS} {\em
<   suboptimality}: when the \hbox{DBMS} chooses a slower plan over a faster
---
> This paper provides a thorough investigation into \hbox{DBMS}
> suboptimality: when the \hbox{DBMS} chooses a slower plan over a faster
195,208c213,235
< query performance and the interaction between operators, especially in a
< dynamic environment, an experimental approach is needed.
< Our research introduces a novel approach
< to better understand the factors influencing query performance in
< \hbox{DBMSes}. Based on existing research and general knowledge of \hbox{DBMSes}, we
< propose an innovative predictive model to better understand the presence and influence
< of suboptimality in query evaluation. We use an experimental methodology on
< a collection of \hbox{DBMSes} as subjects to test our hypotheses with respect to factors
< influencing suboptimality, utilizing
< experiment data collected over a \hbox{cumulative} 16,000 hours (over two
< years) of query executions.
< Our research falls within creative development of
< new evaluation methods and metrics for artifacts, which were identified as
< important design-science contributions~\cite{hevner04}.
---
> query performance and the relationship between operators, especially in a
> dynamic environment, an experimental approach is needed.  Based on existing
> research and general knowledge of \hbox{DBMSes}, we propose an innovative
> predictive model of suboptimality in query evaluation. From this point on,
> by ``suboptimality'' we mean specifically ``empirical suboptimality,''
> indicated by the presence of another plan that can be empirically determined
> to be faster than the plan that was chosen by the query optimizer. Indeed,
> as we will elaborate in Section~\ref{sec:suboptimality}, where we provide a
> specific operationalization of this notion, empirical suboptimality is a
> {\em continuous variable}, indicating the degree to which plans across a
> range of table cardinalities are slower than other (empirically-identified)
> plans. This contrasts with the conventional notion of query plan
> suboptimality, which is a binary {\em categorical variable} associated with
> a particular cardinality: a plan is either optimal (the best-performing
> plan) or it is suboptimal.
> 
> We employ an experimental methodology on a collection of \hbox{DBMSes} as
> subjects to test our hypotheses with respect to factors influencing
> suboptimality, utilizing empirical data collected over a \hbox{cumulative}
> 16,000 hours (over two years) of query executions.  Our research falls
> within creative development of new evaluation methods and metrics for
> artifacts, which were identified as important design-science
> contributions~\cite{hevner04}.
210c237
< \pagebreak
---
> %\pagebreak
224,225c251,252
<   through correlational and regression analysis that four
<   hypothesized interactions are strongly supported, one is weakly in the
---
>   through correlational and regression analyses that four
>   hypotheses are strongly supported, one is weakly in the
231,233c258,261
<   added to the DBMS, and show that current relational DBMSes may have
<   already reached the stage where it is difficult to provide performance
<   improvement via new operators, and in fact performance may degrade.
---
>   added to the DBMS, and show (a)~that there is a {\em limit} to the number of
>   relational operators that a DBMS can accommodate before slower plans start
>   to dominate and (b)~that one or more extant relational DBMSes may have
>   already reached that limit.
236c264
<   engineering directions.
---
>   engineering~directions.
240,241c268,269
<   different from that utilized over the last forty years, may be required
<   to get past a fundamental limitation uncovered in this research.
---
>   different from the cost-base approach utilized over the last forty years, may be required
>   to get past the fundamental limitation uncovered in this research.
272,277c300,310
< optimization. The query optimization phase within a \hbox{DBMS} ostensibly finds the fastest
< query execution plan from a potentially large set of enumerated plans, all of
< which correctly compute the specified query. Occasionally the \hbox{``optimizer''}
< selects a suboptimal plan, for a variety of reasons. We define {\em
<   suboptimality} as the existence of a query plan that performs more
< efficiently than the plan chosen by the query optimizer. From the engineering
---
> optimization. The query optimization phase within a \hbox{DBMS} ostensibly
> finds a fast query execution plan, drawn from a potentially large set of enumerated plans, all of
> which correctly compute the specified query. (The term ``query optimizer'' is thus aspirational rather
> than realistic: the goal of the optimizer isn't really to find the best
> plan, but rather to avoid the worst plans.) However, this intermediate goal
> might not always be realized in practice, for several possible reasons. One is
> that it may not be practical to enumerate all possible plans, and so the
> fastest plans, or even the fast plans, may not be considered. Also, because
> the optimized chooses a plan based on its estimated query execution time, if
> that estimate is of, the optimizer may instead choose a different, less
> efficient plan. From both a scientific perspective and an engineering
283,284c316
< identifies four 
< factors that may play a role in suboptimality. The ultimate goal is to {\em
---
> identifies five constructs that may play a role in suboptimality. The ultimate goal is to {\em
293c325
< causal model of suboptimality and state seven specific hypotheses derived
---
> causal model of suboptimality and state six specific hypotheses derived
297c329
< we are aware of that apply {\em across} \hbox{DBMSes}, rather than on a
---
> we are aware of that apply {\em across} multiple \hbox{DBMSes}, rather than on a
300,304c332,336
< demonstrates a fundamental limit to the number of operators that a
< cost-based optimizer can support, and indicates that perhaps extant DBMSes
< have hit that limit. This model has implications listed in
< Section~\ref{sec:engineering} for research in engineering more efficient
< \hbox{DBMSes}.
---
> uncovers a previously-unknown fundamental limit to the number of operators that a
> cost-based optimizer can support, and shows that this limit may have already
> been reached by one or more extant DBMSes.
> We explore in Section~\ref{sec:engineering} implications of the model for
> research in engineering more efficient \hbox{DBMSes}.
320c352
<         WHERE (t2.id4=t1.id1 AND t2.id1=t0.id1)
---
>         WHERE t2.id4=t1.id1 AND t2.id1=t0.id1
349,350c381,382
< executed at adjacent cardinalities when the plan changed, termed the
< ``query-at-cardinality'' (Q@C) time. For some transitions, the Q@C time at
---
> executed at adjacent cardinalities, termed the
> ``query-at-cardinality'' (Q@C) time, when the plan changed. For some transitions, the Q@C time at
353,356c385,389
< was smaller, such as the transition from plan P1 at 1,650,000 to P0 at 1,640,000
< tuples. Such pairs identify suboptimal plans. For the pair at 720,000
< tuples, P0 required 2.35sec whereas P1 at a larger cardinality required only
< 2.41sec. This query exhibits seven plan change points, two of which are suboptimal.
---
> was {\em smaller}, such as the transition from plan P1 at 1,650,000 to P0 at 1,640,000
> tuples\todo{Young, what were the times?}. Such {\em change pairs}, where the time at the
>   higher cardinality is shorter, identify suboptimal plans. For the change pair at 720,000
> tuples, P0 required 2.35sec whereas P1 at a larger cardinality required
> 2.41sec (as is common, the plan at the higher cardinality takes more time). This query exhibits seven plan change pairs, two of which are suboptimal.
369,370c402,403
< around us: {\em every} \hbox{DBMS} that we have examined, including several
< open source \hbox{DBMSes} and several proprietary
---
> around us: {\em every} \hbox{DBMS} that we have examined, including two
> open source \hbox{DBMSes} and two proprietary
372c405
< phenomena, even when optimizing very simple queries. In the Confirmatory
---
> phenomena, even for very simple queries. In the Confirmatory
412c445
<   6,967 query instances, of which 5,475 had at least one change point, so those are
---
>   6,967 query instances, of which 5,475 had at least one change pair, so those are
416c449
< 1,951 (36\% of the query instances with a change point) have the higher cardinality
---
> 1,951 (36\% of the query instances with a change pair) have the higher cardinality
513c546
< subject~\hbox{\cite{Ioannidis03,Mannino88}}, including proposals for
---
> \hbox{subject~\cite{Ioannidis03,Mannino88}}, including proposals for
526c559
< all, that is the raison d'etre for this phase. As is well known and has been
---
> all, that is the raison d'\^etre for this phase. As is well known and has been
584c617
< predictive model that explicitly states the interactions between these
---
> predictive model that explicitly states the relationships between these
601,602c634,635
< variable will have on the one dependent variable, query suboptimality (with
< some of the the influences mediated by one of the constructs). In
---
> variable will have on the one dependent variable, query Suboptimality (with
> some of the influences mediated by one of the constructs). In
619c652
< to the complexity of the optimizer and concomitant unanticipated
---
> to the complexity of the optimizer and concomitant 
632,633c665,666
< variable, {\em suboptimality}, on the far right. We observe this dependent
< variable in our experiments by determining whether each particular query,
---
> variable, {\em Suboptimality} (as noted in Section~\ref{sec:intro}, specifically, {\em empirical query suboptimality}), on the far right. We observe this \hbox{dependent
> }variable in our experiments by determining whether each particular query,
641c674
< variables which influence suboptimality.
---
> variables which influence Suboptimality.
655c688
< presence of secondary indexes expands the number of possible plans: each
---
> Presence of secondary indexes expands the number of possible plans: each
666,667c699
< (that is, either {\tt Max} or {\tt Avg}) appears in the SELECT clause.
< The third
---
> ({\tt Sum}) appears in the SELECT clause. The third
676c708
< ``Percentage of skewed data''.  Skew is generally defined as how values are
---
> ``Presence of skewed data''.  Skew is generally defined as how values are
680c712
< entire column. The presence of skew complicates query time estimation, which
---
> entire column. The Presence of skew complicates query time estimation, which
697c729
< cost), and can thus count ``the number of operators with
---
> cost), and can thus count the ``Number of operators with
713c745
<   schema complexity and query complexity and the construct of suboptimality.
---
>   schema complexity and query complexity and the construct of Suboptimality.
724c756
< \subsection{Interactions in the Model}\label{sec:interactions}
---
> \subsection{Hypotheses in the Model}\label{sec:hypotheses}
727c759
< these variables, depicted as directed arrow between variables (a line
---
> these variables, each depicted as a directed arrow between variables (a line
729,731c761,762
< variables in that construct). Such relationships are specific {\em interactions} between
< the the constructs (in particular, between their associated variables), as hypothesized by
< this predictive causal model.
---
> variables in that construct). The causal model predicts specific hypotheses  between
> the the constructs (in particular, between their associated variables).
746c777
< indirect interaction through plan space complexity.
---
> indirect effect through plan space complexity.
751,752c782,783
< combinations is exponential to number of correlation names), to number of
< repeats (number of repeats could partially track CEPS), and number of
---
> combinations is exponential to the number of correlation names), to Number of
> repeats (Number of repeats could partially track CEPS), and Number of
755,756c786,787
< We also expect a positive relationship between presence of aggregate (as
< that will definitely add at least one operator to the query plan), presence
---
> We also expect a positive relationship between Presence of aggregate (as
> that will definitely add at least one operator to the query plan), Presence
758c789
< presence of subquery.
---
> Presence of subquery.
775c806
< {\bf Hypothesis 3}: Percentage of skewed data will be negatively correlated with Suboptimality.
---
> {\bf Hypothesis 3}: Presence of skewed data will be negatively correlated with Suboptimality.
780,781c811,812
< number of plans considered by the optimizer increases, so should CEPS, which
< could increase the number of operators with discontinuity that is observed.
---
> Number of plans considered by the optimizer increases, so should CEPS, which
> could increase the Number of operators with discontinuity that is observed.
783c814
< The model also has two interactions within plan space
---
> The model also predicts two correlations within plan space
785c816
< CEPS and number of operators with discontinuity variables and between number of repeats.
---
> CEPS and Number of operators with discontinuity variables and between Number of repeats.
789,790c820,821
< occurrences of suboptimality is not necessarily dependent on the presence
< of a discontinuous plan operator. However, we predict that when
---
> occurrences of suboptimality is not necessarily dependent on the Presence
> of an operator with discontinuity. However, we predict that when
807c838
< We thus hypothesize that the number of repeats has a positive correlation with CEPS. 
---
> We thus hypothesize that the Number of repeats has a positive correlation with CEPS. 
825,828c856,858
< model, serving as a {\em moderator} of two interactions previously
< introduced. We hypothesize that the overall effect of the secondary indexes
< is to increase the strength of the interaction between query
< complexity to plan space complexity. (Note that as the presence of primary
---
> model, serving as a {\em moderator} of two relationships introduced above We hypothesize that the overall effect of the secondary indexes
> is to increase the strength of the relationship between query
> complexity and to plan space complexity. (Note that as the Presence of primary
870c900
< In this section we specify how we operationalized each of the seven
---
> In this section we specify how we operationalized each of the seven independent
872,878c902,907
< of a \hbox{DBMS} (number of operators available), of the schema (presence
<   of secondary indexes), of a query (number of correlation names,
< presence of an aggregate, presence of primary key attribute, and
< presence of subquery), of the data (percentage of skewed data), and of
< the plan space (number of repeats, CEPS, and number of discontinuous
< operators). There is 
< one dependent variable of our model (suboptimality).
---
> of a \hbox{DBMS} (Number of operators available), of the schema (Presence
>   of secondary indexes), of a query (Number of correlation names,
> Presence of an aggregate, Presence of primary key attribute, and
> Presence of subquery), of the data (Presence of skewed data), and of
> the plan space (Number of repeats, CEPS, and Number of operators with discontinuity). There is 
> one dependent variable of our model (Suboptimality).
883c912
< considered, nor the details of how the plans are selected. But such access
---
> considered, nor the details of how the plans were selected. But such access
885c914
< such access is not practical. But by designing the experiment to examine
---
> such access is not feasible. But by designing the experiment to examine
900,901c929,931
< By ``number of operators available in the \hbox{DBMS}'' we mean the \hbox{number} of operators
< available for selection, projection, join and aggregate functions. Our
---
> By ``Number of operators available'' we mean the \hbox{number} of operators
> available in the \hbox{DBMS} for selection, projection, join and aggregate
> functions (that is, potentially relevant for our queries). Our
903c933
< which to evaluate each query. Across the available \hbox{DBMSes}, as the number of
---
> which to evaluate each query. Across the available \hbox{DBMSes}, as the Number of
910c940
< query at at least one cardinality by that \hbox{DBMS}. The number of operators used
---
> query at at least one cardinality by that \hbox{DBMS}. The Number of operators used
916c946
< The presence of secondary indexes is easy to operationalize. We generate two
---
> Presence of secondary indexes is easy to operationalize. We generate two
924c954
< SELECT clause, a few tables referenced in the FROM clause, a few
---
> SELECT clause, a few tables \hbox{referenced} in the FROM clause, a few
929c959
< considered. Concerning presence of primary key attribute, if this independent
---
> considered. Concerning Presence of primary key attribute, if this independent
940c970
< attributes, hence, an average of 2.5 attributes. The number of
---
> attributes, hence, an average of 2.5 attributes. The Number of
946,947c976,977
< number of correlation names, as the presence of self-joins reduced the
< number of unique tables referenced by the queries.
---
> Number of correlation names, as the Presence of self-joins reduced the
> Number of unique tables referenced by the queries.
949,952c979,982
< For the query in Section~\ref{sec:motivation}, the number of correlation
< names is 3, the presence of an aggregate
< is false (0), the presence of primary key attribute is false (0),
< and the presence of subqueries is false (0).
---
> For the query in Section~\ref{sec:motivation}, the Number of correlation
> names is 3, the Presence of an aggregate
> is false (0), the Presence of primary key attribute is false (0),
> and the Presence of subqueries is false (0).
957c987
< eliminated\c2j{.}{\shorten{({\tt cartesianPossible="false"})}}  We do this by
---
> eliminated\c2j{.}{\shorten{({\tt cartesianPossible="false"})}.}  We do this by
978c1008
< The presence of subquery was 0 or 1, with 0 indicating no
---
> The value of Presence of subquery was 0 or 1, with 0 indicating no
980,982c1010,1012
< rendered it as a subquery to replace an attribute in the where clause of the
< original generated query. As an example when this variable was one, we
< started with query qs1-2, shown here.
---
> rendered it as a subquery to replace an attribute in the WHERE clause of the
> original generated query. The following query is an example where this
> variable had a value of 1.
1005c1035
< This independent construct has one variable: percentage of skewed data.
---
> This independent construct has one variable: Presence of skewed data.
1018c1048
< We define the skew as ``the reciprocal of the number of distinct
---
> We define the skew as ``the reciprocal of the Number of distinct
1025c1055
< 1 to the number of distinct values.  This creates a ``span of values.'' We
---
> 1 to the Number of distinct values.  This creates a ``span of values.'' We
1032c1062
< 1.99K tuples. (We then get a query plan for this table.)  We repeat this
---
> 1.99M tuples. (We then get a query plan for this table.)  We repeat this
1037c1067
< values. Since we don't touch the remaining spans, the number of distinct
---
> values. Since we don't touch the remaining spans, the Number of distinct
1083c1113
< The number of repeats is just the number of times a plan associated with a
---
> The Number of repeats is just the number of times a plan associated with a
1095c1125
< To operationalize the ``number of operators with discontinuity'' we
---
> To operationalize the ``Number of operators with discontinuity'' we
1098c1128
< to identify the plan change points, which provide the {\em effective plan
---
> to identify the plan change pairs, which provide the {\em effective plan
1106c1136
< integer as the operationalization of ``number of discontinuous operators''
---
> integer as its operationalization
1134c1164
< to 2M in steps of 10K, or 200 points).  Figure~\ref{fig:discontinuity}
---
> to 2M in steps of 10K, or 200 cardinalities in all that were examined).  Figure~\ref{fig:discontinuity}
1137,1139c1167,1170
< each plan at a particular cardinality. Each distinct point type depicts an
< individual hash-join operator.  This
< figure shows only a small portion of the 200 cardinalities, and is typical
---
> each plan at a particular cardinality. Each distinct point in the graph
> depicts the computed cost of an individual hash-join operator over an input
> table of the indicated cardinality (showing only a small portion of the 200
> cardinalities).  This figure is typical
1197c1228
< \subsection{Suboptimality}\label{sec:suboptimality}
---
> \subsection{Empirical Suboptimality}\label{sec:suboptimality}
1261c1292
< the runtime would also monotonically decrease. However, due to the variance in query
---
> the run time would also monotonically decrease. However, due to the variance in query
1293c1324
< for the largest experiment (Experiment 7: Confirmatory) across all
---
> for the largest experiment (Experiment~7: Confirmatory) across all
1298c1329
< We can now turn to suboptimality. Recall that the monotonicity test examines
---
> We can now turn to empirical suboptimality. Recall that the monotonicity test examines
1300,1301c1331,1332
< suboptimality, we look for adjacent {\QatC}s with {\em different plans}, termed
< a ``change point,'' mentioned earlier. We look for such change points where the computed
---
> suboptimality, we look for adjacent {\QatC}s with {\em different plans}, the
> ``change pairs'' mentioned earlier. We look for such change pairs where the computed
1314c1345
< Our definition of suboptimality compares the computed runtimes 
---
> Our definition of suboptimality compares the computed run times 
1316c1347
< point (designated as $n-1$) and at the change point (that is, $n$).
---
> pair (designated as $n-1$) and at the change pair (that is, $n$).
1322c1353
< At each Q@C pair, Suboptimality is coded as four levels (0--3), based on the distance in 
---
> For each Q@C pair, Suboptimality is coded as four levels (0--3), based on the distance in 
1350c1381,1382
< (the change points) to arrive at a single integer for the query instance.
---
> (the change pairs) to arrive at a single integer for the query instance,
> thus determining the {\em empirical suboptimality of that query instance}.
1353,1354c1385,1386
< to actually execute the query at pairs of cardinality that are change
< points.  Since many fewer {\QatC}s were involved, we could try many more
---
> to actually execute the query at change
> pairs.  Since many fewer {\QatC}s were involved, we could try many more
1356c1388
< described in Section~\ref{sec:experiments}, the value of suboptimality ranged
---
> described in Section~\ref{sec:experiments}, the value of Suboptimality ranged
1397c1429
< 10.5\% of the query executions and 5.1\%
---
> 10.5\% of the query executions (QEs) and 5.1\%
1445c1477
< We are interested in predicting the behavior of \hbox{DBMSes} through our
---
> We are interested in predicting the suboptimal behavior of \hbox{DBMSes} through our
1496c1528
< the primary goals of TTPv2 was (i)~to reduce the number of QEs discarded due to
---
> the primary goals of TTPv2 was (i)~to reduce the number of query executions discarded due to
1502c1534
< The queries came from 19 query sets, summarized below with more details in
---
> The queries came from 16 query sets, summarized below with more details in
1509c1541
< varied between the experiments, but not between the query executions (QEs)
---
> varied between the experiments, but not between the QEs
1523,1524c1555,1556
< we timed each query at {\em all} cardinalities, generating 2,000 \QatC s for
< each query instance), and thus
---
> we timed each query ten times at {\em all} cardinalities, generating 200
> \QatC s for each query instance), and thus
1549,1554c1581,1586
< variables yet also had more complex interactions. Specifically, the model
< did not include the independent query complexity variables of presence of
< secondary indexes, presence of subquery, nor the schema complexity
< independent variable of presence of secondary indexes, nor the plan space
< complexity independent variable of number of repeats. The prior model also
< had presence of primary keys in the schema complexity construct rather than
---
> variables yet also had more complex relationships. Specifically, the model
> did not include the independent query complexity variables of Presence of
> secondary indexes, Presence of subquery, nor the schema complexity
> independent variable of Presence of secondary indexes, nor the plan space
> complexity independent variable of Number of repeats. The prior model also
> had Presence of primary keys in the schema complexity construct rather than
1566,1568c1598,1599
< We ran the \hbox{DBMSes} only on the {\em
<   change points}: adjacent cardinalities (10K apart; 300 for one \hbox{DBMS}) with different
< plans, unlike the Exhaustive experiments. The protocol retained about 78\% of the QEs. 
---
> We ran the \hbox{DBMSes} only on the
> change pairs, unlike the Exhaustive experiments. The protocol retained about 78\% of the QEs. 
1620c1651
< both sides of adjacent {\QatC}s (53,547 change points in all).
---
> both sides of adjacent {\QatC}s (53,547 change pairs in all).
1624,1625c1655
< of a total of 452,684 pairs
< of two Q@Cs having identical plans and query instance), which provides
---
> of a total of 452,684 Q@C pairs having identical plans and query instance), which provides
1628c1658
< operationalization of suboptimality is a valid one.
---
> operationalization of Suboptimality is a valid one.
1639,1640c1669,1670
< Let illustrate the descriptive statistics with the Confirmatory
< experiment. In that experiment, we started with 7,640 query instances. These
---
> To illustrate the descriptive statistics with the Confirmatory
> experiment, we started with 7,640 query instances. These
1645,1647c1675,1676
< Q@C sanity checks in the protocols (657 in all), leaving a remaining 6,983 retained query
< instances. Additionally, 16 query instances were dropped {\em after} the
< protocol because they were missing data for the only change point in the
---
> Q@C sanity checks in the protocols (657 in all), with 6,983 query instances retained. Additionally, 16 query instances were dropped {\em after} the
> protocol because they were missing data for the only change pair in the
1658c1687
< suboptimality  (i.e., level 3) at some Q@C pair.
---
> Suboptimality  (i.e., level 3) for at least one change pair.
1667c1696,1697
< fundamental aspect of either the algorithm (cost-based optimization) or the
---
> fundamental aspect of either the 
> \hbox{algorithm} (cost-based optimization) or the
1671,1672c1701,1702
< \pagebreak
< Third, concerning the causal factors of suboptimality in our model,
---
> %\pagebreak
> Third, concerning the causal factors of Suboptimality in our model,
1677c1707
< \item the number of instances of discontinuous operators observed in plans for a query
---
> \item the Number of operators with discontinuity observed in plans for a query
1679c1709
< \item the number of repeats ranged from 0 to 108, with the mean being 4.99.
---
> \item the Number of repeats ranged from 0 to 108, with the mean being 4.99.
1709c1739
< Presence of primary key & -- & {\bf H2g:} {\em NS} & {\bf H2h:} 0.15 & {\bf H2i:} 0.14\\
---
> Presence of primary key attribute& -- & {\bf H2g:} {\em NS} & {\bf H2h:} 0.15 & {\bf H2i:} 0.14\\
1713c1743
< Skew & {\bf H3:} {\em -0.05} & --- & ---  & ---\\
---
> Presence of skewed data & {\bf H3:} {\em -0.05} & --- & ---  & ---\\
1715c1745
< Repeats& {\bf H6a:} 0.62 & --- & --  & ---\\
---
> Presence of repeats& {\bf H6a:} 0.62 & --- & --  & ---\\
1719c1749
< Discontinuity & {\bf H6c:} 0.47 & --- & --- & ---\\
---
> Number of operators with discontinuity & {\bf H6c:} 0.47 & --- & --- & ---\\
1737,1738c1767,1768
< not directly measure {\em per-operator times}: we were only able to measure
< {\em per-plan times}, that is, for each Q@C.) The estimated cost reported by
---
> not directly measure {\em per-operator run times}: we were only able to measure
> {\em per-plan run times}, that is, for each Q@C.) The estimated cost reported by
1743c1773
< operator'' incorrectly classifies some operators, due to the vagaries in the
---
> operator'' incorrectly classified some operators, due to the vagaries in the
1749,1750c1779,1780
< not supported because the correlation between Presence of skew (recall from
< Section~\ref{sec:datacomplexity} that absence is skew is operationalized as
---
> not supported because the correlation between Presence of skewed data (recall from
> Section~\ref{sec:datacomplexity} that absence of skew is operationalized as
1752c1782
< and Suboptimality was in the opposite direction. Specifically, we observed a negative correlation,
---
> and Suboptimality was in the \hbox{opposite} direction. Specifically, we observed a negative correlation,
1754c1784
< decreases, though only slightly: \hbox{-0.05}.
---
> decreases, though only slightly:~\hbox{-0.05}.
1763c1793
< interaction strength for Presence of Primary Key Attribute in the presence
---
> interaction strength for Presence of primary key attribute in the presence
1795c1825
< is well-understood.
---
> is well understood.
1813c1843
< 7.23\% of the variance of number of repeats, 40.9\% of the variance of CEPS, and 35.7\% of the variance
---
> 7.23\% of the variance of Number of repeats, 40.9\% of the variance of CEPS, and 35.7\% of the variance
1816c1846
< 7.23\% of the variance of number of repeats, 41.1\% of the variance of CEPS, and
---
> 7.23\% of the variance of Number of repeats, 41.1\% of the variance of CEPS, and
1823c1853
< \shorten{We did regressions on the causal variables for CEPS, number of repeats and for number of
---
> \shorten{We did regressions on the causal variables for CEPS, Number of repeats and for Number of
1825c1855
< variance for CEPS, 7.23\% of the variance for number of repeats, and 38.9\% of the variance for
---
> variance for CEPS, 7.23\% of the variance for Number of repeats, and 38.9\% of the variance for
1830,1831c1860,1861
< model explained 53.6\% of the variance of the suboptimality dependent
< variable. That means that over half of the variance of suboptimality is
---
> model explained 53.6\% of the variance of the Suboptimality dependent
> variable. That means that over half of the variance of Suboptimality is
1835c1865
< To state this a different way, all other possible causes for suboptimality
---
> To state this a different way, all other possible causes for Suboptimality
1854,1855c1884,1885
< the presence of an aggregate and CEPS were significant at the 0.05 level, yet
< our model explains fully \% of the suboptimality variance (and \% of the
---
> the Presence of an aggregate and CEPS were significant at the 0.05 level, yet
> our model explains fully \% of the Suboptimality variance (and \% of the
1862c1892
< predicting the suboptimality dependent variable, were CEPS at , number
---
> predicting the Suboptimality dependent variable, were CEPS at , number
1877c1907
< via the Exhaustive \hbox{Experiment}, and number of operators available, via the
---
> via the Exhaustive \hbox{Experiment}, and Number of operators available, via the
1912c1942
< the regression \hbox{coefficient} that was highest was for number of repeats (0.46, normalized). The next \hbox{highest}
---
> the regression \hbox{coefficient} that was highest was for Number of repeats (0.46, normalized). The next \hbox{highest}
1918c1948
< The next most influential factor is the number of discontinuous operators
---
> The next most influential factor is the Number of operators with discontinuity
1920c1950,1951
< \hbox{implicating} the cost model. The final factor is Presence skew (-0.057, normalized), a small effect that has the salutary effect of
---
> \hbox{implicating} the cost model. The final factor is Presence of skewed
> data (-0.057, normalized), a small effect that has the salutary effect of
1927,1931c1958,1963
< In order to increase query performance, \hbox{DBMSes} are extended over time
< with new \hbox{relational} query operators. Also over time, \hbox{DBMSes}
< are extended with new storage and indexing structures, which themselves
< elicit new query operators. For example, nested loop join was probably the
< first implementation of this needed algebraic operator. B-tree index join
---
> One oft-used way to increase DBMS query performance is for the developer to
> add to the DBMS source code another physical operator that can be then used
> in query evaluation plans~\cite{Graefe93}.
> 
> For example, nested loop join was probably the
> first implementation of the relational join algebraic operator. B-tree index join
1934c1966,1969
< adding hash indexes enables (perhaps several variants of) hash-index join. Each
---
> adding hash indexes enables (perhaps several physical variants of)
> hash-index join.
> 
> Each
1936,1937c1971,1998
< collection of operators, with the current incarnation the most recent
< within a series of \hbox{DBMS} {\em generations}.
---
> collection of physical operators, with the current incarnation the most recent
> within a series of \hbox{DBMS} {\em generations}. (The study discussed in
> this paper above was over a recent generation of each DBMS.)
> 
> With this new physical operator
> available, the set of possible plans is expanded, and for certain
> combinations of query and data, there could be a plan that uses that new
> operator that is fast than any plan that can be expressed without that
> operator. In any case, the performance of the best plan for each query/data
> combination won't get slower, because all prior plans are still
> available. That is why the number of physical operators grows over the
> releases of a DBMS.
> 
> However, this ideal behavior might not always be seen in practice, for
> several possible reasons. One is that it may not be practical to enumerate
> all possible plans, and so the fastest plan may not even be
> considered. Indeed, query optimization is NP-complete, even when using only
> one physical join operator~\cite{Ibaraki84}. Also, because the optimizer is
> choosing a plan based on its estimated query execution time, if that
> estimate is off, the optimizer might not choose the plan with the fastest
> actual execution time. Thus, if the new plan, with that additional operator,
> is estimated to be faster than the current chosen plan, the new plan may be
> chosen even though its actual execution time may be slower than another
> candidate plan.
> 
> This raises a central question: {\em does an additional operator made
>   available in a release of a DBMS to speed up some queries actually help or
>   hurt the overall performance of that DBMS?}
1940,1942c2001,2005
< Consider a Gedanken experiment that examines the plan for each query at
< each cardinality, that is, each Q@C, {\em for each \hbox{DBMS} generation}. In early
< generations, there will be few plan changes for a given query as the cardinality varies,
---
> Consider a Gedanken experiment over DBMS {\em generations}. The experiment
> considers the plan selected for each query at each possible cardinality,
> that is, each Q@C, {\em for each \hbox{DBMS} generation that adds an
>   operator}. In early generations, there will be few plan changes for a
> given query as the cardinality varies, 
1944c2007
< subsequent generations, some of the Q@Cs will be associated with different plans,
---
> later generations, some Q@Cs will be associated with different plans
1949,1952c2012,2013
< generation. After all, that is the very reason the new operator(s) were
< added to that subsequent generation.  However, in the presence of
< suboptimality, sometimes the new plan at that Q@C is {\em not} preferable,
< as that \hbox{DBMS} generation's query optimizer selected the wrong plan.
---
> generation. After all, that is the very reason the new operator was
> added to that subsequent generation.  However, sometimes that \hbox{DBMS} generation's query optimizer selected a slower plan.
1954c2015
< generation, in part to minimize the chance of selecting the wrong plan.
---
> generation, in part to minimize the chance of selecting a slower plan.
1956c2017
< Our predictive model in Figure~\ref{fig:model} suggests that suboptimality
---
> Our predictive model in Figure~\ref{fig:model} suggests that Suboptimality
1963c2024
< operators available contributed 9.21\% of the variance of Suboptimality.
---
> operators available accounted for 9.21\% of the variance of Suboptimality.
1966c2027
< is that as the evolution of generations of the \hbox{DBMS} add more and more
---
> is that as the evolution of generations of the \hbox{DBMS} adds more and more
1972,1973c2033,2034
< page~\pageref{sec:intro}: Our goal, up to this point, has been ``to \hbox{understand} cost-based query
< optimizers
---
> page~\pageref{sec:intro}: our goal thus far has been ``to \hbox{understand}
> cost-based query optimizers
1979c2040
< the query optimizer {\em across multiple
---
> the query optimizer {\em across multiple DBMS
1984c2045
< Let's then refine our Gedanken experiment. Let's assume each subsequent
---
> As a refinement, let's assume each subsequent
2009,2010c2070,2071
< operators increases, the latent measures of plan space complexity increase,
< which therefore also {\em increase} suboptimality. As the generations of the
---
> operators increases, the intervening measures of plan space complexity increase,
> which therefore also {\em increase} empirical suboptimality. As the generations of the
2014,2025c2075,2084
< subset of Q@Cs for any given query, while the suboptimality occurs in a portion over an
< {\em expanding} subset of Q@Cs, our causal model implies that the curve of
< per-generation time will fall (improve) with each successive generation, but then
< start to level off as suboptimality becomes more prevalent.
< Eventually, the
< per-generation time will either asymptotically approach a horizontal line
< (with the first derivative approaching 0 from below), or worse: the first
< derivative will change to positive, with the per-generation time over the
< queries we are studying actually {\em increasing} with \hbox{DBMS}
< generation. In either case, the causal model predicts a point where {\em the
< \hbox{increase} in execution time due to suboptimality obviates the decrease
< enabled by the new operator}.
---
> subset of Q@Cs for any given query, while slower plans can emerge over an
> {\em expanding} subset of Q@Cs, our causal model implies that performance
> will improve with each successive generation, but then
> start to level off as optimizer missteps becomes more prevalent.
> The causal model predicts a point where {\em the
> \hbox{increase} in execution time due to further missteps obviates the decrease
> enabled by the new operator}. This seems to be a fundamental limitation
> inherent in cost-based query optimization, due to the inherent inaccuracy of
> the cost model and the difficulty of enumerating all plans for queries over
> many table.
2031c2090,2091
< Does such a limit exist, and if so, how close are modern \hbox{DBMSes} to that limit?
---
> \vspace{1ex}
> {\em Does such a limit exist, and if so, how close are modern \hbox{DBMSes} to that limit?}
2036c2096
< approximate this with an experiment using the data already collected on the
---
> using the data already collected on the
2038,2040c2098,2099
< generations, each successively having a fewer number of operators, and thus a smaller set of
< realizable query plans. (The effect will probably be smaller in our
< simulation, as we are nonetheless using the most recent query
---
> generations, each successively having one additional operator, and thus a
> larger set of realizable query plans. (Note that we use the most recent query
2042c2101
< will vary.)
---
> will vary across generations.)
2044c2103
< In the next section, we'll explain how we characterize the generations of
---
> In the next section, we will explain how we characterize the generations of
2051,2052c2110,2113
< the previous study. Specifically, we focus on pairs of adjacent
< Q@Cs (let's refer to them as the {\em lower} Q@C and the {\em upper} Q@C,
---
> the previous study. Specifically, we focus on the adjacent (that is,
> separated by the minimum cardinality, either 10,000 or 300 rows) Q@Cs within
> change pairs 
> (let's refer to these as the {\em lower} Q@C and the {\em upper} Q@C,
2054,2059c2115,2118
< same query at the {\em lower} and {\em upper} cardinalities, that are
< adjacent (that is, separated by the minimum cardinality, either 10,000 or
< 300 rows), each with an actual execution time. All Q@Cs for that query and
< for that DBMS having cardinalities between the upper Q@C of one pair and the
< lower Q@C of the next pair are associated with that same plan. This will be
< the upper plan, guaranteed by the process in which we chose those Q@Cs for
---
> same query at the {\em lower} and {\em upper} cardinalities, each with an actual execution time. All Q@Cs for that query and
> for that DBMS having cardinalities between the upper Q@C of one change pair and the
> lower Q@C of the next (higher) change pair are associated with that same plan,
> guaranteed by the process in which we chose those Q@Cs for
2067c2126
< plan associated with that Q@C. We also only consider Q@C pairs (with adjacent Q@Cs) where the lower
---
> plan associated with that Q@C. We also only consider change pairs where the lower
2072,2074c2131,2136
< highest cardinality of 2M rowsm, then later at 1320 rows (this is the
< measured Q@C that has Plan A that is closest to the measurement at 910K rows), then a pair of Q@Cs with Plan A at 910K rows and Plan B at the
< adjacent 900K rows, then later Plan B at 400K rows and then Plan A again at 30K rows.
---
> highest cardinality of 2M rows, then later at 1320K rows (this is the
> measured Q@C that has Plan A that is closest to the measurement at 910K
> rows), then a change pair with Plan A at 910K rows and Plan B at the
> adjacent 900K rows, then later Plan A again at 30K rows. (We show only a few
> Q@Cs in this example; there are other change pairs that are not relevant to
> our discussion.) 
2088,2089c2150,2151
< was chosen is that it is faster than Plan A at that cardinality, shown in
< the figure by extrapolating the time down from 910K down to 900K (we will
---
> was chosen is that it was faster than Plan A at that cardinality, shown in
> the figure by extrapolating the run time down from 910K down to 900K (we will
2094c2156
< more operators available chooses the {\em wrong} plan, one that is slower
---
> more operators available chooses a plan that is slower
2099,2101c2161,2163
< (\hbox{enabled} by the additional operator(s) in that generation) represent a win (runs faster)
< or a loss (runs slower, because of suboptimality)? More broadly, do the Q@Cs
< in the aggregate enabled by each succeeding generation continue to overcome
---
> (\hbox{enabled} by the additional operator in that generation) represent a win (runs faster)
> or a loss (runs slower)? More broadly, do the Q@Cs
> in the aggregate enabled by each successive generation continue to overcome
2118,2119c2180,2181
< at change points, that is, maximizing the number of Q@Cs, containing just that
< operator. So for example, all the plans generated by MySQL that have exactly
---
> at change pairs, that is, maximizing the number of Q@Cs, containing just that
> operator. So for example, all the plans generated by DBMS A that have exactly
2123c2185
< operator can be constructed by MySQL generation 1, as well as by any
---
> operator can be constructed by generation 1, as well as by any
2127c2189
< Using MySQL again, there are two such: one with the Full Table Scan and
---
> Using DBMS A again, there are two such: one with the Full Table Scan and
2137c2199
< The generations of MySQL thus can be characterized from the Q@Cs we encountered: five distinct combinations of two
---
> The generations thus can be characterized from the Q@Cs we encountered: five distinct combinations of two
2155c2217
< \subsection{Number of Change Points Per Generation}\label{sec:CPQ}
---
> \subsection{Number of Change Pairs Per Generation}\label{sec:CPQ}
2157,2158c2219,2220
< performance through the lens of change points, let's consider  the {\em
<   maximum number of change points per query}, or {\em maximum CPQ}, from the
---
> performance through the lens of change pairs, let's consider  the {\em
>   maximum number of change pairs per query}, or {\em maximum CPQ}, from the
2170c2232
< \tbl{Max Change Points Per Query, Per Generation\label{tab:maxcpq}}{%
---
> \tbl{Max Change Pairs Per Query, Per Generation\label{tab:maxcpq}}{%
2173c2235
< {\em Generation}&{\em Maximum Change Points}\\
---
> {\em Generation}&{\em Maximum Change Pairs}\\
2203c2265
< there is a query that has an astonishingly high number of change points,
---
> there is a query that has an astonishingly high number of change pairs,
2204a2267,2268
> This analysis indicates that there is something concerning change pairs that seems to get
> critical around generation 8. We'll return to this in Section~\ref{sec:hitthewall}.
2206,2216c2270,2272
< This analysis indicates that there is something concerning that seems to get
< critical around generation 8.  And indeed, for this data set, we'll see in
< Section~\ref{sec:hitthewall} that the efficacy of the query optimizers
< bottom out around that generation.
< 
< \subsection{Using Change Points}\label{sec:usingCP}
< We now consider how to use data already collected, that is the {\em change
<   points} discussed in Section~\ref{sec:experiments}: adjacent
< cardinalities (10K apart; 300 for one \hbox{DBMS}) with different
< plans. Specifically, how can change points be used to evaluate the
< effectiveness of different generations of a \hbox{DBMS}?
---
> \subsection{Using Change Pairs}\label{sec:usingCP}
> We now consider how change pairs can be used to evaluate the
> effectiveness of different generations of a \hbox{DBMS}.
2220,2221c2276,2277
< A generation $g$ (also a set of operators) is {\em applicable} to a plan $p$ if
< $\hbox{\em ops}(p) \subseteq g$. By
---
> A plan $p$ is {\em applicable} to a DBMS generation $g$ (denoted by a set of
> operators) if $\hbox{\em ops}(p) \subseteq g$. By
2223,2224c2279,2280
< applicable to all subsequent generations. The smallest such generation is
< termed the {\em minimally applicable generation}, or {\em mingen}.
---
> applicable to all subsequent generations, with one being the 
> {\em earliest applicable generation}, or {\em mingen}.
2248,2249c2304,2306
< As each change point consists of a pair of adjacent Q@Cs, we have two generations
< to consider. Lets start with pairs for which $\hbox{\em
---
> For each change pair, containing adjacent Q@Cs, we have either one or two
> generations to consider. We focus on change pairs with two generations, and start with
> those for which $\hbox{\em 
2257c2314
< pair are wildly different.)
---
> change pair are quite different.)
2266,2267c2323,2324
< To examine the wisdom of picking Plan A for 900K (whose time was measured as
< the {\em higher} point shown (the one above the dashed line), we find the closest Q@C
---
> To examine the wisdom of picking Plan A for 900K (whose run time was measured as
> the {\em higher} point pair shown, the one above the dashed line), we find the closest Q@C
2270c2327
< we can't do the extrapolation, and simply remove that change point from
---
> we can't do the extrapolation, and simply remove that change pair from
2273,2274c2330,2333
< We use the slope of the dashed line between the measured query time of Plan
< B at cardinalities 30K and 910K to get an estimated query time at 900k.
---
> We then extrapolate the measured time for the closest plan of the lower
> generation to the cardinality of the adjacent higher generation. In this
> particular case, we use the measured query time of Plan
> B at cardinalities 30K and 910K to extrapolate an estimated query time at 900K.
2283,2284c2342,2343
< incremented, but the time is linear for a set number of passes.
< The presence of a change in the number of passes, say between 30K and 910K,
---
> incremented, but the query time is linear for a set number of passes.
> Returning to the situation in Figure~\ref{fig:posback}, the presence of a change in the number of passes, say between 30K and 910K,
2286c2345
< this extrapolation will slightly underestimate the runtime of
---
> this extrapolation will slightly underestimate the run time of
2293c2352
< backward from a cardinality of 910K to one of 900K.
---
> backward from a cardinality of 910K to one of 900K, within the change pair.
2295,2296c2354,2355
< With this extrapolation, we can compute the {\em relative delta}, defined as the
< measured time of Plan A (the chosen one) at the lower cardinality (900K) minus the
---
> With this extrapolation, we can compute, for each change pair, the {\em relative delta}, defined as the
> measured time of Plan A (the chosen one) at the lower cardinality (here, 900K) minus the
2298c2357,2358
< measured time of Plan A. The relative delta is then scaled by original
---
> larger of the measured and extrapolated time of the plan at the higher
> generation (here, Plan A). The relative delta is thus scaled by original
2303c2363
< time), which indicates that the optimizer chose the {\em wrong plan}: here,
---
> time), which indicates that the optimizer chose a slower plan: here,
2314,2315c2374,2378
< Summarizing, a
< positive relative delta (extrapolated in either the forward or backward direction) implies the presence of suboptimality: the wrong
---
> Summarizing, this analysis computes, for a {\em change pair} (a pair of
> adjacent Q@Cs for a specific query running on a specific DBMS), a {\em
>   relative delta} for the earliest applicable generation. A
> positive relative delta (extrapolated in either the forward or backward
> direction) reflects that a slower
2317,2326c2380,2389
< operators available. A negative relative delta (forward or backward) implies the {\em absence} of
< suboptimality: the chosen plan was faster at that cardinality than the one
< chosen at the adjacent cardinality. (Note that this is a slightly more expansive definition
< of suboptimality than that used earlier and illustrated in
< Figure~\ref{fig:query769}.)
< 
< There are six orthogonal possibilities for each change point (that
< is, a pair of adjacent Q@Cs), a total of 66,769 pairs/change
< points from the Exploratory and Confirmatory Experiments. (There is also the
< case of a query instance containing a lone Q@C, which we don't consider further.)
---
> operators available. A negative relative delta (forward or backward) reflects
> that the chosen plan was faster at that cardinality than the one
> chosen at the adjacent cardinality.
> 
> There are ten orthogonal possibilities for each change pair (that
> is, a pair of adjacent Q@Cs), a total of 66,792 change
> pairs from the Exploratory and Confirmatory Experiments. (There is also the
> case of a query instance containing a lone Q@C, meaning that only one plan was
> chosen across all 200 Q@Cs. This occurred for 2126 out of the 8840
> query instances, which we don't consider further.)
2330c2393,2394
< \hbox{\em mingen}(\hbox{\em upper})$  (62,903 Q@C pairs, 94.2\%), which we don't consider further.
---
> \hbox{\em mingen}(\hbox{\em upper})$  (62,903 change pairs, or 94.2\% of the
> total), which we don't consider further.
2333c2397
< time that was negative, which we also drop (10 pairs, 0.01\%).
---
> time that was negative, which we also drop (10 change pairs, 0.01\%).
2335c2399
< \item The extrapolation from above and indicating
---
> \item The extrapolation was from above and indicated
2338,2339c2402,2403
<   exemplified in Figure~\ref{fig:negback}, examined earlier (492 pairs,
<   0.7\%).
---
>   exemplified in Figure~\ref{fig:negback}, examined earlier (583 change pairs,
>   0.9\%).
2342,2343c2406,2407
<     relative delta} and exemplified in Figure~\ref{fig:posback}, indicates
<   a suboptimal plan (583 pairs, 0.9\%).
---
>     relative delta} and exemplified in Figure~\ref{fig:posback}, indicated
>   a suboptimal plan (492 change pairs, 0.7\%).
2346c2410
<   indicating no suboptimality (1218 pairs, 1.8\%).
---
>   indicating no suboptimality (795 change pairs, 1.2\%).
2352c2416,2427
<   indicating a suboptimal plan (795 pairs, 1.2\%).
---
>   indicating a suboptimal plan (1218 change pairs, 1.8\%).
> 
> \item The pair had an upper plan that was newer but no forward extrapolation
>   was possible (54 change pairs, 0.05\%).
> 
> \item The pair had a lower plan that was newer but no backward extrapolation
>   was possible (224 change pairs, 0.3\%).
> 
> \item The pair had a relative delta of -1 (2 change pairs, 0.002\%).
> 
> \item The pair had a relative delta of 1 (11 change pairs, 0.01\%).
> 
2355,2357c2430,2436
< From these six possibilities, we thus retain (3) and (5), which indicate a
< \hbox{suboptimal} plan at the later generation (1710 pairs), and (4) and (6), which indicate a
< non-suboptimal plan at the later generation (1378 pairs).
---
> From these ten possibilities, we thus retain (3) and (5), which indicate a
> slower plan at the later generation (1710 pairs), and (4) and (6), which indicate a
> faster plan at the later generation (1378 pairs).
> 
> \subsection{Realizing the Gedanken Experiment}\label{sec:realizing}
> We now have the components in place for performing an experiment that
> parallels the Gedanken experiment described in Section~\ref{sec:gedanken}.
2359d2437
< \subsection{Trends Across \hbox{DBMS} Generations}\label{sec:trends}
2368c2446,2449
< is not affected by the query nor even which \hbox{DBMS} is involved. We associate
---
> is not affected by the query nor even which \hbox{DBMS} is involved. *DBMSes
> vary greatly in the evaluation time of individual queries; using the actual
> query time would artificially give more weight to change pairs from the
> slowest DBMS.) We associate
2373,2376c2454,2457
< DBMSes, and then computed for each generation, might behave across successive
< generations.
< The average relative delta is a characterization of the aggregate
< impact of that generation, providing a quantitative estimate of the benefit
---
> DBMSes, of query plans associated with that individual generation, might
> behave across successive generations.
> The average relative delta for an individual generation is a characterization of the
> aggregate impact of the query plans associated with that generation, providing a quantitative estimate of the benefit
2378c2459,2461
< by the number of pairs over which that point is computed.)
---
> by the number of change pairs over which that point is computed. Note that
> this approach weights the queries equally. This makes sense for our queries,
> summarized in Section~\ref{sec:experiments}; those queries are quite similar.)
2384c2467
< subsequent generations, the latent measures in plan space complexity increase, which
---
> subsequent generations, the intervening measures in plan space complexity increase, which
2390c2473,2474
< operators, suboptimality will also increase.
---
> operators, optimizer missteps will increase and possibly dominate. What is
> the correspondence with the realizable experiment we are now considering?
2392,2393c2476,2477
< If we plot the performance of the DBMS on the {\em y}-axis, say as the
< total time for a workload consisting of a set of queries over a
---
> If we plot the {\em performance} of the DBMS on the {\em y}-axis for a
> workload consisting of a set of queries over a 
2396c2480,2482
< of the {\em slope} of this relationship. A negative average relative delta
---
> of the {\em slope} of this relationship. (Since {\em more} performance is
> good, we negative the average relative delta, as that measure concerns query
> time, with {\em less} query time indicating {\em greater} performance.) A negative average relative delta
2398c2484,2485
< suboptimality, and so the total workload execution time will go down; a
---
> suboptimality, and so the total workload execution time will go down and
> performance will go up; a
2401c2488
< generation.
---
> generation, and thus performance going down.
2403,2404c2490,2491
< We expect that the average relative delta for the first few generations will
< be negative, reflecting new operators that improves some plans, a natural
---
> We expect that the negated average relative delta for the first few generations will
> be positive, reflecting new operators that improve some plans, a natural
2406,2407c2493,2494
< successive generations of their \hbox{DBMS}.  With a negative slope, the
< performance plot will decrease over successive DBMS generations.
---
> successive generations of their \hbox{DBMS}.  Hence, the
> performance plot will is expected to grow over successive DBMS generations.
2412,2413c2499,2500
< our causal model predicts that the prevalence of suboptimality would
< increase as the number of operators available increased.  It seems that even
---
> our causal model predicts that the prevalence of suboptimality will
> increase as operators are added.  It seems that even
2415c2502
< that the average relative delta (itself a slope of the performance curve)
---
> that the average relative delta 
2417c2504,2505
< more prevalent.
---
> more prevalent. This analysis suggests then that the performance curve will
> level off and then start dropping off.
2419,2431c2507
< This analysis suggests then that the performance curve will thus start to
< level off. That raises the
< possibility of the performance curve either asymptotically approaching a horizontal line
< (the first derivative approaching 0), or worse: the first derivative (the
< average relative delta)
< changing to positive, with the average time over the queries we are studying
< actually {\em increasing} with \hbox{DBMS} generation. 
< 
< So the question comes down to this:  {\em by
< how much} is the increase in efficiency enabled by a new operator (for those
< Q@Cs utilizing a plan containing that operator) greater than the decrease in
< efficiency resulting from suboptimality (for a subset of those Q@Cs)
< resulting from adding that operator? Is there a
---
> So the question comes down to this:  {\em Is there an empirically-determined
2433,2510c2509,2510
< by the new operator: a DBMS generation where the average relative delta
< becomes positive? How close might modern \hbox{DBMSes} be to that limit?
< 
< \subsection{Have Modern DBMSes Hit The Wall?}\label{sec:hitthewall}
< We partition the relevant four sets of change points discussed in the
< Section~\ref{sec:usingCP} into two groups: (i)~those
< with a {\em positive} relative delta (either forward or backward), denoting a
< {\em suboptimal decision} by the query optimizer at the later generation
< (corresponding to a higher generation number)
< and (ii)~those with a {\em negative} relative delta (either forward or
< backward) relative delta, indicating a {\em non-suboptimal decision} by the
< query optimizer at the later generation. (We can't state unequivocally that
< the plan is optimal, because there may be yet another plan involving the
< operators within that generation that is even faster.)
< 
< Let's first examine those change points for which the query optimizer made a
< good decision, the non-suboptimal change points; see
< Table~\ref{tab:non-subopt}.
< 
< The first thing to note is that this data aggregates the results over the
< four \hbox{DBMSes}, which had generations ranging from five to 13. Thus this is the
< first study we are aware of that compares the generational trends of \hbox{DBMSes}
< over quite disparate code bases, thus getting at fundamental trends.
< 
< Overall, only a small number of change points, 1378, or about 2\% of the
< total, satisfied the requirements listed above, including having a different
< generation number for the lower and upper plans. In fact, there were no such
< change points for the first three generations nor for the last
< generation. The second column states the number of change points added by
< that generation and the average relative delta across just those change
< points. The last column states the {\em cumulative relative delta} for that
< generation, defined as
< the sum of the average relative delta for those change points associated
< with plans having only operators in its generation, divided by the number of
< change points. This is the relevant number for a generation, as it includes
< all plans that would have been emitted by that generation, using the
< operators at that generation's disposal.
< 
< The numbers jump around quite a bit, especially for the first few
< generations. The thing to focus on is the last column, where the cumulative
< relative delta starts off at a low of
< -0.28 (recall that low negative value is good, as it indicates the
< additional operator was effective at lowering the execution time) and slowly increasing to -0.225:
< more negative numbers trending to less negative
< numbers, indicating decreasing benefits of optimization.
< 
< This general behavior matches our prediction arising from the structural causal model that it
< gets harder to squeeze out performance gains as operators are added to the
< \hbox{DBMS} over successive generations.
< 
< We now examine those change points for which the query optimizer made a poor
< decision, in that we can surmise that there was a better plan (the one right
< next to it in the adjacent Q@C pair). Table~\ref{tab:subopt} provides the
< same information across the \hbox{DBMS} generations for the suboptimal change
< points: those for which the
<   relative deltas are positive, indicating a poor decision, as the query
<   time increased. While there are
<   still only a small number of change points, there are a greater number of
<   {\em suboptimal} change points, with a relatively greater number showing up at more
<   recent generations. But more strikingly, the cumulative relative delta has
<   the opposite behavior to the non-suboptimal change points: it {\em
<     increases} over the generations (indicating greater suboptimality), starting at 0.077 and ending at 0.246, a
<   value {\em higher} than that of the non-suboptimal change points.
< 
< The next-to-last column brings the non-suboptimal and suboptimal together, stating
< the {\em net cumulative relative delta}, gathering the change points
< with plans that would have been generated by that DBMS generation
< together. We see that the net starts out \hbox{at -0.24}, indicating that the new
< operators are {\em decreasing} the query time for the
< workload. Unfortunately, this happy situation starts to deteriorate: with
< each successive generation, the improvement is less. This is as predicted:
< the optimizer is struggling with both more options (plans over the available
< operators) to select from and a diminished opportunity to make a significant
< improvement.
< 
< We also see that at Generation 10, the net actually becomes very slightly positive: meaning that the performance
< curve has hit a minimum and is now on its way up, towards slower
< performance. This trend increases in later generations.
---
> by the new operator: a DBMS generation where the performance actually drops,
> as predicted? How close might modern \hbox{DBMSes} be to that limit?}
2511a2512,2530
> \subsection{Trends Across DBMS Generations}\label{sec:trends}
> We partition the relevant four sets of change pairs discussed in the
> Section~\ref{sec:usingCP} into two groups. The first group consists of those
> change pairs with a {\em positive}
> relative delta (either forward or backward), indicating that the query
> optimizer selected a slower plan at the later generation (corresponding to a
> higher generation number), thereby denoting an (empirically) {\em suboptimal
>   decision} by the query optimizer at that later generation. The second
> group consists of those change pairs 
> with a {\em negative} relative delta (either forward or backward) relative
> delta, indicating that the query optimizer selected a faster plan at the
> later generation, which was thus an (empirically) {\em non-suboptimal
>   decision} at that later generation. Note that we can't state
> unequivocally that the plan will a negative relative delta is optimal (in the
> original, absolute, sense of that term) because there may be a yet another
> plan involving the operators 
> within that generation that is even faster. That said, in the other case, a positive relative
> delta reliably asserts that the plan at this Q@C is \hbox{demonstrably}
> {\em empirically suboptimal}, and thus also is suboptimal in the absolute case.
2514c2533
< \tbl{Non-Suboptimal Change Points\label{tab:non-subopt}}{%
---
> \tbl{Beneficial Change Pairs\label{tab:non-subopt}}{%
2518c2537
< & {\em Change Points} & {\em Relative Delta} & {\em Relative Delta}\\
---
> & {\em Change Pairs} & {\em Relative Delta} & {\em Relative Delta}\\
2540c2559
< \tbl{Suboptimal Change Points\label{tab:subopt}}{%
---
> \tbl{Deleterious Change Pairs\label{tab:subopt}}{%
2542,2546c2561,2563
< \begin{tabular}{c|c|c|c|c|c}
< {\em Generation}&{\em Number of} &{\em Average}&{\em Cumulative}&{\em Net
<   Cumulative}&{\em Relative}\\
< & {\em Change Points} & {\em Relative Delta} & {\em Relative Delta}& {\em
<   Relative Delta}&{\em ``Performance''}\\
---
> \begin{tabular}{c|c|c|c}
> {\em Generation}&{\em Number of} &{\em Average}&{\em Cumulative}\\
> & {\em Change Pairs} & {\em Relative Delta} & {\em Relative Delta}\\
2548,2561c2565,2578
< 1 & --- & ---   & ---   &---   &---\\
< 2 & --- & ---   & ---   &---   &--\\
< 3 & --- & ---   & ---   &---   &0\\
< 4 & 2   & 0.2   & 0.2   &-0.24 &-0.24\\
< 5 & 211 & 0.076 & 0.077 &-0.045&-0.285\\
< 6 & 86  & 0.16  & 0.102 &-0.103&-0.388\\
< 7 & 263 & 0.303 & 0.196 &-0.0800&-0.468\\
< 8 & 273 & 0.303 & 0.231 &-0.0256&-0.493\\
< 9  & 3  & 0.04  & 0.230 &-0.0257&-0.519\\
< 10 & 168& 0.319 & 0.245 &0.00750 &-0.512\\
< 11 & 639& 0.237 & 0.242 &0.0296&-0.482\\
< 12 & 53 & 0.35  & 0.245 &0.0346&-0.448\\
< 13 & 12 & 0.40  & 0.246 &0.0360&-0.412\\
< {\em Cumulative}& 1710& ---  & 0.246 &0.0360&---\\
---
> 1 & --- & ---   & ---  \\
> 2 & --- & ---   & ---  \\
> 3 & --- & ---   & ---  \\
> 4 & 2   & 0.2   & 0.2  \\
> 5 & 211 & 0.076 & 0.077\\
> 6 & 86  & 0.16  & 0.102\\
> 7 & 263 & 0.303 & 0.196\\
> 8 & 273 & 0.303 & 0.231\\
> 9  & 3  & 0.04  & 0.230\\
> 10 & 168& 0.319 & 0.245\\
> 11 & 639& 0.237 & 0.242\\
> 12 & 53 & 0.35  & 0.245\\
> 13 & 12 & 0.40  & 0.246\\
> {\em Cumulative}&1710&---&0.246\\
2567,2572c2584,2677
< The final column integrates the net cumulative relative delta to produce a unit-less
< {\em relative performance}, a simulation of how the four DBMSes together
< would have performed (say, in total execution time) on the workload of the Confirmatory
< Experiment, or rather the 1378 change points selected by the criteria in
< Section~\ref{sec:usingCP}. (We emphasize that our experiment estimates just
< the first derivative of the performance graph, the net cumulative
---
> We first examine those change pairs for which the query optimizer made a
> good \hbox{decision}: the non-suboptimal change pairs, summarized in
> Table~\ref{tab:non-subopt} and designated as {\em beneficial}.
> This data aggregates the results over the
> four \hbox{DBMSes}, which had generations ranging from five to thirteen. Overall, only a small number of change pairs, 1378, or about 2\% of the
> total, satisfied the requirements listed in Section~\ref{sec:usingCP}, including having a different
> generation number for the lower and upper plans. In fact, there were no such
> change pairs for the first three generations nor for the last
> generation. The second column states the number of change pairs added by
> that generation and the third column the average relative delta across just those change
> pairs. The last column states the {\em cumulative relative delta} for that
> generation, defined as
> the sum of the average relative delta for those change pairs associated
> with plans having only operators in its generation, divided by the number of such
> change pairs. It thus
> includes the change pairs associated with all previous generations,
> again, as those plans all include operators made available by that generation.
> 
> The averages jump around quite a bit, especially for the first few
> generations. (One of the reasons is that the number of change pairs
> associated with an individual generation varies a
> lot.) \hbox{Focusing} on the last column, we see that the cumulative
> relative delta starts off at a low of
> -0.28 (recall that a negative value is good, as it indicates the
> additional operator was effective at lowering the execution time) and slowly
> increases to -0.225, or more negative numbers trending to less negative
> numbers, indicating decreasing benefits of optimization.
> 
> This general behavior matches our prediction arising from the structural
> causal model: it gets harder for the DBMS query optimizer to squeeze out
> performance gains as operators are added to the \hbox{DBMS} over successive
> generations.
> 
> We now examine those change pairs for which the query optimizer made a poor
> decision, in that we can conclude that there was a better plan (the one
> right next to it in the change pair), designated as {\em deleterious}. Table~\ref{tab:subopt} provides the
> same information across the \hbox{DBMS} generations for the suboptimal
> change pairs: those for which the relative deltas are positive, indicating a
> decision that increased the query time. While there are still only a small
> number of such change pairs, there are more deleterious than beneficial
> pairs, with a relatively greater number showing up at more recent
> generations. (Half of the beneficial change pairs occurred before generation
> 8, but half of the deleterious change pairs showed up only in generation 10
> or higher.) More strikingly, the cumulative relative delta has the opposite
> behavior to the \hbox{non-suboptimal} change pairs (which showed decreasing
> benefits): it {\em increases} over the generations (indicating greater
> suboptimality), starting at 0.077 and ending at 0.246, a value {\em higher}
> than that of the non-suboptimal change pairs. Both trends were as predicted.
> 
> \subsection{Have Modern DBMSes Hit The Wall?}\label{sec:hitthewall}
> Table~\ref{tab:performance} brings the beneficial and deleterious change
> pairs together, stating the total number of change pairs associated with
> each generation and the {\em average net relative delta}, again, just for
> change pairs associated with that generation. 
> 
> \begin{table}[t]
> \tbl{Assembled Change Pairs and Relative ``Performance''\label{tab:performance}}{%
> %\begin{center}
> \begin{tabular}{c|c|c|c}
> {\em Generation}&{\em Number of} &{\em Average Net}     &{\em Cumulative Net}\\
>             & {\em Change Pairs} & {\em Relative Delta} &{\em Relative Delta}\\
> \hline
> 1           & ---                & ---                  & ---\\
> 2           & ---                & ---                  & ---\\
> 3           & ---                & ---                  & ---\\
> 4           & 26                 & ?                    & -0.24\\
> 5           & 493                & ?                    & -0.045\\
> 6           & 395                & ?                    & -0.103\\
> 7           & 599                & ?                    & -0.0800\\
> 8           & 316                & ?                    & -0.0256\\
> 9           & 7                  & ?                    & -0.0257\\
> 10          & 185                & ?                    & 0.00750\\
> 11          & 996                & ?                    & 0.0296\\
> 12          & 59                 & ?                    & 0.0346\\
> 13          & 12                 & ?                    & 0.0360\\
> {\em Cumulative}& 3088           & ---                  & 0.0360\\
> \end{tabular}
> %\end{center}
> }
> \todo{Young: could you provide the third column? It's the average just for
>   the change pairs for that generation.}
> \end{table}
> 
> The final column in Table~\ref{tab:performance} provides the
> cumulative net relative delta.  This column thus reflects all the change pairs
> with plans that would have been generated by that DBMS generation
> (hence, including change pairs at that generation along with those
> at previous generations). This value provides an indicator of how the four
> \hbox{DBMSes} together would have performed (say, in total execution time) on the
> workload of the Exploratory and Confirmatory
> Experiments, or rather on the 3088 change pairs selected by the criteria in
> Section~\ref{sec:usingCP}. (We emphasize that our experiment estimates with
> empirical results just
> the first derivative of the performance graph, the cumulative net 
2574a2680,2700
> thus only very roughly indicative of the {\em shape} of the performance
> graph.)
> 
> We see that the cumulative net relative delta starts out \hbox{at -0.24}, indicating
> that the new operators are {\em increasing} the performance (by
> {\em decreasing} the query time) for the workload. This happy situation
> unfortunately starts to deteriorate: after generation 6, with each
> successive generation, the performance deteriorates. This is as predicted:
> the optimizer is struggling with both more options (plans over the available
> operators) to select from and a diminished opportunity to make a significant
> improvement.
> 
> \shorten{OLD: The final column of Table~\ref{tab:subopt} integrates the
>   average relative delta to produce a unit-less
> {\em relative performance}, an indicator of how the four DBMSes together
> would have performed (say, in total execution time) on the workload of the
> Exploratory and Confirmatory
> Experiments, or rather on the 1378 change pairs selected by the criteria in
> Section~\ref{sec:usingCP}. (We emphasize that our experiment estimates just
> the first derivative of the performance graph, the average relative delta, and then only for a small
> number of Q@Cs, and then only as a relative measure, between -1 and 1. It is
2578c2704
< relative performance actually gets worse (slower, indicated by a rising value).
---
> relative performance actually gets worse (slower, indicated by a rising value).}
2581c2707
<     \subfigure[Cumulative Average Relative Delta over Generations]{
---
>     \subfigure[Cumulative Relative Deltas]{
2597c2723,2727
<     \caption{Trend of Performance Improvement over Generations}
---
> \todo{Young: Please remove the ``Net Cumulative Relative Delta'' curve in
>   the middle and instead put it as 10(b).}
> \todo{Young: also replace ``Suboptimal'' with
>   ``Deleterious (suboptimal)'' and ``Not suboptimal'' with ``Beneficial (not suboptimal)''}
>     \caption{Trend of Relative Performance over Generations}
2601c2731
< Figure~\ref{fig:benefit} and \ref{fig:performance} tell the story
---
> Figure~\ref{fig:machine_comp} tells the story
2603,2617c2733,2745
< Table~\ref{tab:non-subopt} as the top line (non-suboptimal cumulative
< relative data), the fourth column of Table~\ref{tab:subopt} as the bottom
< line (suboptimal cumulative relative delta), and the fifth column of
< Table~\ref{tab:subopt} as the middle line (net cumulative relative delta)
< in the center. This middle line has a least squares slope of 0.024, which
< is consistent with the transition from a generation being net beneficial to
< actually being slightly suboptimal around generation 10 and more so at later
< generations. Figure~\ref{fig:performance} plots the last column of
< Table~\ref{tab:subopt}, the relative performance across generation. This
< illustrates visually that the performance time falls (gets better) until
< around generation 10, after which adding an operator might have an overall
< detrimental impact, actually slowing down the query.
< 
< In summary, the engineering perspective in Section~\ref{sec:gedanken}
< predicts that the overall per-generation time would ``monotonically decrease
---
> Table~\ref{tab:non-subopt} as the bottom line (beneficial: non-suboptimal cumulative
> relative delta) and the last column of Table~\ref{tab:subopt} as the top
> line (deleterious: suboptimal cumulative relative delta).
> Figure~\ref{fig:performance} plots the ``Relative Performance'', that is,
> the negation of the cumulative net relative delta (as a positive relative
> delta denotes a slower query, reflecting decreased performance) appearing as the
> last column of Table~\ref{tab:subopt}, as this characterizes the relative
> performance across generations. This line has a least squares slope of
> -0.024.
> 
> \subsection{Summary}
> The engineering perspective in Section~\ref{sec:gedanken}
> predicts that the overall per-generation run time would ``monotonically decrease
2619,2624c2747,2748
< perspective, using our validated causal model, reaches the opposite conclusion: ``the
< per-generation time will either asymptotically approach a horizontal line
< (with the first derivative approaching 0 from below), or worse: the first
< derivative will change to positive, with the per-generation time over the
< queries we are studying actually increasing with \hbox{DBMS}
< generation. In either case, the causal model predicts a point where the
---
> perspective, applying our validated causal model, reaches the opposite
> conclusion: there will be a point where ``the
2629,2630c2753,2754
< This highly aggregated result, extracting 3000-odd change-point pairs having
< the specified properties of interest stated in Section~\ref{sec:trends} and
---
> This highly aggregated result, extracting 3000-odd change pairs having
> the specified properties of interest stated in Section~\ref{sec:usingCP} and
2635,2640c2759,2768
< related problem cropped up around generation 8.
< 
< It is important to emphasize that we can't say whether any of these DBMSes have actually
< transitioned to where, for this class of queries, the errors of the
< suboptimal change points overwhelm the benefits of the non-suboptimal change
< points. Presumably, the DBMS vendors have done extensive tests to ensure
---
> related problem cropped up around generation 8.  This is the
> first study we are aware of that compares the generational trends of
> \hbox{DBMSes} over quite disparate code bases, thus getting at fundamental
> trends. 
> 
> It is important to emphasize that we can't say from this one study
> whether any of these DBMSes have actually
> transitioned to where, for this class of queries, the cost of the
> suboptimal change pairs overwhelm the benefits of the non-suboptimal change
> pairs. Presumably, the DBMS vendors have done extensive tests to ensure
2644c2772
< strongly point to a decreasing benefit and an increasing cost. as predicted
---
> strongly point to a decreasing benefit and an increasing cost, as predicted
2646c2774
< reached the point of diminishing returns, that possibility exists.
---
> reached the point of diminishing returns, that possibility looms in the future.
2650c2778
< range of data, with only a small percentage (3\%) of change points
---
> range of data, with only a small percentage (3\%) of change pairs
2653c2781
< (as Hypothesis 2 in Section~\ref{sec:interactions} states). Also, relational
---
> (as Hypothesis 2 in Section~\ref{sec:hypotheses} states). Also, relational
2657c2785
< extremely simple), and (iii)~range of table cardinalities (the smallest
---
> extremely simple), and (iii)~range of table cardinalities (our smallest
2660c2788,2789
< minimize the suboptimality observed.
---
> minimize the suboptimality observed. Thus, more complex workloads may
> present an even higher degree of empirical suboptimality.
2664c2793
< phenomenon, suboptimality, when the \hbox{optimizer} selecting a wrong
---
> phenomenon, suboptimality, when the \hbox{optimizer} selecting a slower
2668,2670c2797,2799
< of suboptimality and its causal factors. The genesis of our predictive model was a sense that suboptimality
< is caused in part by the inherent complexity of these system and the
< concomitant unanticipated interactions between various rules in the
---
> of Suboptimality and its causal factors. The genesis of our predictive model
> was a sense that Suboptimality is caused in part by the inherent complexity
> of these systems and the concomitant interactions between various rules in the
2680c2809
< considered, the optimizer picked the wrong plan for at least one
---
> considered, the optimizer picked a slower plan for at least one
2685c2814
<         the runtime) at some cardinality.
---
>         the run time) at some cardinality.
2689c2818
< this topic. Fortunately, the causal model helps point out
---
> this topic. Fortunately, the causal model can suggest
2742,2743c2871,2872
< might be on the wrong side of the ``jump,'' thereby selecting the wrong
< plan.  That the presence of discontinuous operators has such a high
---
> might be on the wrong side of the ``jump,'' thereby selecting a slower
> plan.  That the Presence of discontinuous operators has such a high
2782,2783c2911,2912
< causal model in Figure~\ref{fig:model}, which correctly predict  the almost
< inexorable rise in net cumulative relative delta, which implies that the
---
> causal model in Figure~\ref{fig:model}, which correctly predicts the almost
> inexorable rise in per-generation assembled relative delta, which implies that the
2801c2930
< optimization, this is the first paper to the authors' knowledge t0 take a
---
> optimization, this is the first paper to the authors' knowledge to take a
2811c2940,2941
<   suboptimality}, {\em query flutter}, and {\em query thrashing}, three problems that have not been systematically investigated across \hbox{DBMSes}, is
---
>   suboptimality}, {\em query flutter}, and {\em query thrashing}, three
>   problems that have not been systematically investigated across multiple \hbox{DBMSes}, is
2832,2839c2962,2972
< \item Uncovers compelling {\em evidence} (a)~that
< suboptimality correlates with four operationalizations of query complexity,
< (b)~that suboptimality correlates with three operationalizations of plan space
< complexity, (c)~that the presence of secondary indexes is a helpful contributor to plan space
< \hbox{complexity,} (d)~that schema complexity, as operationalized by the
< presence of secondary indexes, helpfully though weakly moderates these three
< interactions, and (e)~that the presence of skewed data may diminish
< suboptimality slightly.
---
> \item Uncovers compelling {\em evidence}
> (i)~that (empirical) suboptimality correlates with four operationalizations of query complexity,
> (ii)~that suboptimality correlates with three operationalizations of plan space
> complexity,
> (iii)~that the Presence of secondary indexes is a contributor to plan space
> \hbox{complexity,}
> (iv)~that schema complexity, as operationalized by the
> Presence of secondary indexes, though weakly moderates these three
> interactions, and
> (v)~that the Presence of skewed data may diminish
> Suboptimality slightly.
2847c2980
< of suboptimality.  No other factor, as yet unknown, or combination of factors,
---
> of empirical suboptimality.  No other factor, as yet unknown, or combination of factors,
2853c2986
< \item Articulates for the first time a possible {\em upper bound} on the
---
> \item Articulates for the first time a {\em limit} on the
2860,2862c2993,2995
< \item Applies a novel experiment over pairs of adjacent Q@Cs to show that
<   such an upper bound is probable and may have already been reached by one
<   or more our our subject DBMSes.
---
> \item Applies a novel experiment over pairs of adjacent Q@Cs provides
>   empirical evidence that a limit exists and may have already been reached by one
>   or more our subject DBMSes.
2866,2870c2999,3003
< \item Provides a {\em path toward scientific progress} in the
<   understanding of a key enabling technology. 
<   It is important to emphasize that our model doesn't apply to just one implementation of the
< algorithm or to one \hbox{DBMS}.  Rather, it is quite broad, applying to any \hbox{DBMS}
< with a cost-based optimizer.
---
> \item Provides a {\em path toward scientific progress} in the understanding
>   of a key enabling technology.  It is important to emphasize that our model
>   doesn't apply to just one implementation of the algorithm or to one
>   \hbox{DBMS}.  Rather, it is quite broad, applying to any \hbox{DBMS} with
>   a cost-based optimizer.
2883,2884c3016,3017
< relatively simple, with six constructs and their interactions. Some of the
< predicted interactions were not borne out in the confirmatory testing.
---
> relatively simple, with six constructs and their relationships. Some of the
> predicted relationships were not borne out in the confirmatory analysis.
2893,2894c3026,3027
< Why was the interaction between Number of operators available and Number of
< operators with discontinuity in the opposite direction from hypothesized? As
---
> Why was the direction between Number of operators available and Number of
> operators with discontinuity opposite from hypothesized? As
2953,2954c3086
< variables.''~\cite[p.~106]{kabra98}.  Might there be other unanticipated
< interactions, that are unknown simply because they haven't been
---
> variables.''~\cite[p.~106]{kabra98}.  Might there be other unanticipated relations, that are unknown simply because they haven't been
2967,2968c3099,3100
< other factors impact (at all, and if so, how much) the original constructs
< and interactions. So for example it would be interesting to study how a suboptimal subquery can affect
---
> other factors impact (at all, and if so, how much) these initial constructs
> and relationships. So for example it would be interesting to study how a suboptimal subquery can affect
2983,2984c3115,3116
< One can further ask, for each causal interaction in the model,
< interactions that have been validated in empirical studies, what is it about
---
> One can further ask, for each causal relationship in the model,
> relationships that have been validated in empirical studies, what is it about
2987c3119
< interaction?
---
> relationship?
2989c3121
< It may be that that interaction is {\em baked into the optimizer}. For
---
> It may be that that relationship is {\em baked into the optimizer}. For
2996,2997c3128,3129
< But other interactions may be avoidable, through selection of alternative
< algorithms. After all, this study only generalizes over four DBMSes.
---
> But other relationships may be avoidable, through selection of alternative
> algorithms. After all, this study generalizes over only four DBMSes.
3003,3006c3135,3138
< and off the rules and observing suboptimality. (An example of this is Leis
< et al.'s study of cardinality estimation, cost model, and plan enumeration~\cite{Leis15}.) And it may be possible to
< determine whether certain query rewrite techniques are employed within each
< \hbox{DBMS}, introducing another ``\hbox{DBMS} complexity'' factor into our
---
> and off the rules and observing suboptimality. (An example is a
> study of cardinality estimation, cost model, and plan enumeration~\cite{Leis15}.) And it may be possible to
> determine whether \hbox{certain} query rewrite techniques are employed within each
> \hbox{DBMS}, perhaps introducing other ``\hbox{DBMS} complexity'' factor(s) in our
3013a3146,3173
> The identified limit is inherent in cost-based query
> optimization. Engineering approaches can help ameliorate the effect
> identified here. One approach might be to time query plans as they run
> (effectively introducing an empirical cost model) in order to provide more
> accurate cost estimates, though that is itself time-consuming
> when there is a large plan space. Another that has been proposed is to
> replace multiple physical operators of a logical  operator (in this case,
> the join operator, which can have as physical operators nested-loop,
> sort-merge, hash, and index join) with a single physical operator (in this
> case, g-join) that performs equally or better that the alternative physical
> operators, hopefully in all cases~\cite{Graefe12}. Doing so can reduce
> optimizer errors when choosing between the previously-available multiple
> variants. This approach is aligned with our theoretical and empirical
> results: if adding physical operators gets us close to or beyond the limit
> of performance improvement, as we have
> seen, then removing variants should move the DBMS away from that
> limit. However, the g-join has not yet been demonstrated to be applicable in
> all situations and for all queries, and in any case, the limit still
> remains.
> 
> Engineering solutions to {\em eliminate} the identified limit, to allow
> continued introduction of new operators, thus requires perfecting the cost
> model and making query plan enumeration deterministic, neither of which
> seems to be practical, or adopting an entirely new tact that eschews
> cost-based query optimization entirely, such as a
> learning-based approach or defining a single physical operator for
> each logical operator.
> 
3017c3177
< understand the causal factors and their interactions.
---
> understand the causal factors and their relationships.
3031,3032c3191,3194
< IIS-0415101, and EIA-0080123. We thank Rui Zhang for his help in initiating
< this research, Ricardo Carlos, Preetha Chatterjee, Pallavi
---
> IIS-0415101, and EIA-0080123 and by NRF grant NRF-2011-0020576. We thank Rui Zhang for his help in initiating
> this research. We appreciate helpful discussions and insightful feedback from Melanie
> Brucks, Curtis Dyreson, Christian Jensen, David Maier, Thomas Matheson, Arash Termehchy,
> Abhijit Saha, and Marianne Winslett. Ricardo Carlos, Preetha Chatterjee, Pallavi
3036,3038c3198,3200
< Lopamudra Sarangi, Linh Tran, Cheng Yi, and Man Zhang for
< their contributions to the \hbox{\azdb} and Phil Kaslo, Tom Lowry, and John
< Luiten for constructing and maintaining our experimental instrument\c2j{}{,
---
> Lopamudra Sarangi, Linh Tran, Cheng Yi, and Man Zhang contributed
> to the \hbox{\azdb} and Phil Kaslo, Tom Lowry, and John
> Luiten helped in constructing and maintaining our experimental instrument\c2j{}{,
3045c3207
< Appendix~\ref{sec:app} provides further details on the experiments.
---
> \doubleblind{Appendix~\ref{sec:app} provides further details on the experiments.}{}
3242c3404
< %\newpage
---
> \newpage
3250a3413,3435
> \begin{table}[t]
> \tbl{Experiments 1--7: Detailed Run Statistics\label{tab:run_stat2}}
> {%
> \resizebox{140mm}{!}
> {
> \begin{tabular}{c|c|c|c|c|c|c}
> & {\em Experiment}& {\em Data Sets} & {\em Lab Shelves} & {\em What was} &{\em Was Query}&{\em Number of}\\
> &                 & {\em Used}      &                   & {\em Examined?}&{\em Timed?}   &{\em Retained (Raw)}\\
> &&&&&& {\em Q@Cs}\\
> \hline
> 1 & Monotonicity 	& A & 6.0     &all cardinalities&yes& 12,000 (12,000)\\
> 2 & Exhaustive & A & 5.19 + 6.0&all cardinalities&yes& 27,948 (32,000)\\
> 3\shorten{4} & Exhaustive with Keys & B& 6.0     &change pairs   &no& 40,000 (40,000) \\
> 4\shorten{5} & Initial Exploratory & A + B&5.19 + 5.2 + 6.0&change pairs&yes& 8,171 (8,842)\\
> 5\shorten{3} & Refined Exhaustive & A & 7.1     &all cardinalities&yes & 29,515 (32,000)\\
> 6 & Exploratory 	& A + B&7.1   &change pairs   &yes& 12,100 (12,560)\\
> 7 & Confirmatory 	&A + B + C +D&7.1&change pairs&yes& 94,502 (99,558)\\
> \multicolumn{2}{c|}{\em Total}&      &   &             &   & 184,236 (196,960)\\
> \end{tabular}
> }
> }
> \end{table}
> 
3260c3445
< on the percentage of skewed data. Section~\ref{sec:datacomplexity} provides
---
> on the Presence of skewed data. Section~\ref{sec:datacomplexity} provides
3306c3491,3493
<   outside of that: Rick: Yes, this is part of the scenario code. Specifically, if the presence of secondary indexes is true, or the presence of data skew is false, then in the scenario code an experiment subject creates the indexes or makes no skew when populating tables. After table population is done, the code studies each query, or detects a change point and makes query executions at that change point.}} 
---
>   outside of that: Rick: Yes, this is part of the scenario
>   code. Specifically, if the Presence of secondary indexes is true, or the
>   Presence of skewed data is false, then in the scenario code an experiment subject creates the indexes or makes no skew when populating tables. After table population is done, the code studies each query, or detects a change pair and makes query executions at that change pair.}} 
3324,3346d3510
< 
< \begin{table}[t]
< \tbl{Experiments 1--7: Detailed Run Statistics\label{tab:run_stat2}}
< {%
< \resizebox{140mm}{!}
< {
< \begin{tabular}{c|c|c|c|c|c|c}
< & {\em Experiment}& {\em Data Sets} & {\em Lab Shelves} & {\em What was} &{\em Was Query}&{\em Number of}\\
< &                 & {\em Used}      &                   & {\em Examined?}&{\em Timed?}   &{\em Retained (Raw)}\\
< &&&&&& {\em Q@Cs}\\
< \hline
< 1 & Monotonicity 	& A & 6.0     &all cardinalities&yes& 12,000 (12,000)\\
< 2 & Exhaustive & A & 5.19 + 6.0&all cardinalities&yes& 27,948 (32,000)\\
< 3\shorten{4} & Exhaustive with Keys & B& 6.0     &change points   &no& 40,000 (40,000) \\
< 4\shorten{5} & Initial Exploratory & A + B&5.19 + 5.2 + 6.0&change points&yes& 8,171 (8,842)\\
< 5\shorten{3} & Refined Exhaustive & A & 7.1     &all cardinalities&yes & 29,515 (32,000)\\
< 6 & Exploratory 	& A + B&7.1   &change points   &yes& 12,100 (12,560)\\
< 7 & Confirmatory 	&A + B + C +D&7.1&change points&yes& 94,502 (99,558)\\
< \multicolumn{2}{c|}{\em Total}&      &   &             &   & 184,236 (196,960)\\
< \end{tabular}
< }
< }
< \end{table}
