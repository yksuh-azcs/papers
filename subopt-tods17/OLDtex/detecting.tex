\subsection{Detecting Suboptimality}
\todo{Get adjacent from operationalization.
 assumptions: time query repeatable, timing monotonic}

\todo{Rick has modify token: merge these two sections.}
\todo{ original adjacent scenario, change points, monotonicity}

How might such behavior be observed? We have developed a system, \azdb, that
allows us to perform experiments to study this phenomenon of suboptimality.
\azdb\ can externally modify data
dictionary statistics for tables and columns, thereby allowing the DBMS to
generate different plans for a given query.
\hbox{\azdb} then presents queries to the DBMS while varying
the statistics, in particular the cardinality of one of the tables,
requesting in each case the evaluation plan chosen by the DBMS.
This is done using the
{\tt EXPLAIN} SQL facility available in modern DBMSes. We can thus compare
the performance (execution time) of various plans for the query, to identify those
situations when the wrong plan was chosen, when in fact there was a
different plan that was semantically equivalent to the chosen plan (that is,
yielded the identical result) but which ran faster.

\begin{figure*}[tb]
\centering
%originally 30pc
\epsfig{figure=figures/model.eps,width=30pc}
\caption{Predictive Model of Suboptimality\label{fig:model}}
\end{figure*}

\comment{\azdb\ modifies the cardinality statistics to produce multiple execution
plans for a given query. For one of the DBMSes, we can modify the stored
table statistics directly. For the other DBMSes, we had to do so indirectly,
by varying the size of the table and running the optimizer on tables of
different size. As \azdb\ varies the cardinality statistics of tables, it
collects all the plans that the optimizer felt were appropriate for that
query.  After \azdb\ gathers the plans, it then executes each plan on the
original table(s), to determine which plan was actually the best, of the
plans generated by the optimizer. 
}
It is important to note that all of this manipulation can be done {\em
  outside} the DBMS. For proprietary systems we do not have access to the
internal code. We don't know ({\em can't} know) all the plans that were
considered, nor the details of how the plans are selected. But such access
is not needed; indeed, to be able to study a phenomenon across many DBMSes,
such access is not practical. But by designing the experiment to examine
the plans that the DBMS actually produces, and thus to examine phenomena
that can be externally visible, we can obtain valuable insights into general
classes of computational artifacts. Our ultimate goal is to make statements
that hold across cost-based optimizers in general, thereby moving up the
$y$-axis of Figure~\ref{fig:empirical}.


